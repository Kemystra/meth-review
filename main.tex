\documentclass[a4paper, 12pt]{article}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage[style=apa,backend=biber,natbib=true]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage{enumerate}
\usepackage{amsmath} 
\usepackage[margin=0.5in]{geometry}

\addbibresource{main.bib}


\renewcommand{\baselinestretch}{1.0}

\newcommand\nd{\textsuperscript{nd}\xspace}
\newcommand\rd{\textsuperscript{rd}\xspace}
\newcommand\nth{\textsuperscript{th}\xspace} %\th is taken already

\setlength\parindent{0pt} % set paragraph indent to zero

% fill up your name, ID and paper title here
\author{
IZZMINHAL AKMAL BIN NORHISYAM \quad 242UC240JF \quad contribution1 \\
CHOW YING TONG \quad 242UC244NK \quad contribution2\\
CHOONG JIA XUEN \quad 242UC244K1 \quad contribution3\\
LIM YU XUAN \quad 251UC18043 \quad contribution4\\
}
\title{ REVIEW REPORT  Title  }



\begin{document}
\maketitle


\section{Introduction and Problem Statement}
Artificial intelligence (AI) is undeniably experiencing a rapid growth. This is reflected in the massive increase in the computational resources required to train the latest models. According to \citet{Sevilla_Roldan_2024}, the amount of computational power needed to train the most advanced AI models is growing at a rate of 4 to 5 times per year. This exponential growth means that the environmental impact of AI, which is often overlooked, is compounded even further.

\section{Literature Review}
\subsection{Holistically Analyzing the Carbon Footprint of AI}
The work by \citet{Wu2022} provides a foundational, holistic analysis of the sources of AI's greenhouse gas emissions, shifting the focus beyond prior research that was often limited to the carbon footprint of training a single, massive model. The authors contend that this narrow, model-centric view has become insufficient in the face of the "super-linear growth" of the entire AI ecosystem, a trend characterized by exponential increases in model complexity, vast volumes of training data, and the ever-expanding hardware infrastructure required to support them (p. 2). To provide a more accurate assessment, their analysis expands the scope to encompass two critical dimensions: the end-to-end machine learning pipeline (from data acquisition to inference) and the life cycle of the hardware itself. Critically, the authors introduce a practical framework that distinguishes between operational carbon, defined as the emissions from electricity consumed during use, and embodied carbon, which are the often-hidden emissions generated from the entire manufacturing supply chain (p. 2). Other than that, the authors provide several solutions that could be employed to mitigate the carbon footprint of AI.

\subsection{Holistically Analyzing the Ecological Costs of AI}
The analysis by \citet{Zhuk2023} offers a comprehensive interdisciplinary approach to understanding the hidden ecological costs associated with the development and deployment of AI technologies. Unlike previous studies that often focus narrowly on energy consumption during AI model training, Zhuk expands the scope to include not only the energy-intensiveness of computing operations but also the broader environmental impacts such as the lifecycle emissions of hardware manufacturing, data center energy demands, e-waste generation from rapid equipment obsolescence, and the ecological disruptions caused by AI infrastructure expansion. Importantly, the work highlights how non-renewable energy reliance leads to increased carbon emissions and poses systemic obstacles to sustainable ecological development. Moreover, the study integrates ethical and political-legal dimensions, underscoring how AI-related errors and algorithmic biases can exacerbate environmental injustice and inequality. The author calls for holistic strategies aimed at energy-efficient algorithm design, renewable energy adoption, responsible e-waste management, and the formulation of binding ethical-legal frameworks at multiple governance levels to harmonize AI progress with environmental sustainability.

\subsection{Holistically Analyzing the EVs, AI, and Sustainable Mobility}
The work by \citet{M.rauf2024} offers Global environmental challenges have put tremendous pressure on the transportation sector to transform.  Road transport, which includes more than one billion cars, is a major source of fossil fuel consumption and CO2 emissions, accounting for nearly 90 percent of total road traffic. This dependency is a great problem, given that global CO2 emissions are expected to exceed 37 billion tons in 2023. In addition to that, widespread usage of electric vehicles (EVs), which currently number 26 million worldwide, is an essential move toward meeting the Sustainable Development Goals (SDGs) and Net Zero Emission targets.  The success of this transition is directly related to the use of Artificial Intelligence (AI), which provides intelligent solutions for creating more affordable and efficient EVs. The influence of AI is visible throughout the EV ecosystem. It improves vehicle efficiency by utilizing advanced driver-assistance systems (ADAS) that optimize driving and manage energy use in real time.  Furthermore, AI is critical for grid integration since it allows Vehicle-to-Grid (V2G) systems to intelligently arrange energy exchanges, balance grid loads, and engage vehicle owners in energy programs.

\subsection{Holistically Analyzing the Contribution of AI towards E-Waste Generation}
Generative Artificial Intelligence (GAI), particularly Large Language Models (LLMs), demands intense computational power for training and inference, leading to substantial electronic waste (e-waste) with significant environmental implications. \citet{wang_2024_ewaste} propose a Computational Power-driven Material Flow Analysis (CP-MFA) model to quantify e-waste from AI servers supporting LLMs, estimating that cumulative end-of-service e-waste may reach 16 million tons by 2030 in an optimistic scenario, constituting about 11\% of global e-waste. This e-waste is geographically concentrated mainly in North America, Europe, and East Asia, with a compound annual growth rate of 110\%, far exceeding conventional e-waste growth. The study explores three circular economy strategies—lifespan extension, stepwise upgrading, and module reuse—with lifespan extension proving most effective, potentially reducing e-waste by 58\%. Geopolitical factors, such as semiconductor trade restrictions, can increase e-waste due to lagged computational power and lower hardware efficiency. The discarded servers contain valuable metals (e.g., gold, silver, platinum) and toxic substances (e.g., lead, cadmium), highlighting both economic recycling potential (\~\$70 billion worth of materials) and environmental risks, including soil and water contamination. \citet{wang_2024_ewaste} emphasize the imperative for sustainable dismantling, recycling technologies, and circular economy implementation in the AI server lifecycle. Additionally, repurposing functional outdated servers for smaller-scale educational or enterprise uses is encouraged to extend device utility. Major industry players have begun implementing zero-landfill goals and circular centers for efficient server recycling. The study calls for improved traceability, standardized server status labeling, and integrated recycling systems to manage the concentrated AI hardware waste effectively. Despite some modeling assumptions and uncertainties, the work highlights urgent environmental considerations intrinsic to the GAI boom and advocates multi-faceted strategies including international cooperation, circular economy adoption, and enhanced recycling infrastructure to mitigate the influx of AI-generated e-waste.

\section{Research Methodology}
\subsection{Data Collection and Sourcing}
Based on the study conducted by \citet{Wu2022}, the data was collected from multiple sources, from internal production systems at Meta, external public reports, and experimental modeling to create a holistic view of AI's environmental footprint. The primary data source consisted of extensive internal infrastructure telemetry from Meta's large-scale AI systems, encompassing operational metrics such as data center power consumption logs, GPU utilization rates, model training job durations, and data ingestion bandwidth statistics. To account for the manufacturing footprint, the authors sourced Life Cycle Inventory (LCI) data from external databases and manufacturer publications, such as Apple's Product Environmental Reports, which served as a proxy for their own hardware components (p. 5). For the purpose of comparative analysis, the study also incorporated the publicly available carbon footprint results of other prominent models, including GPT-3 and Meena, to contextualize their own findings (p. 5). Finally, to model the energy consumption of specific edge-computing use cases like federated learning, the authors constructed their estimations using a combination of experimental measurements, including device power profiles from Android (p. 19) and network bandwidth data from public sources.\hfill \break

In addition, the study by \citet{Zhuk2023} leverages comprehensive data on the environmental impacts of AI that extends to manufacturing supply chains, hardware lifecycle assessments, and ecosystem-level influences. The data collection process integrates metrics of energy consumption and associated carbon emissions at each stage of AI system deployment, including electronic waste generation and renewable energy utilization. Ethical-legal impact data were also considered by incorporating existing regulatory frameworks and case studies on AI-related environmental injuries and risks to communities, thus providing a multidisciplinary dataset that enriches the environmental footprint assessment of AI technologies.\hfill \break

In the study by \citet{wang_2024_ewaste} the researchers developed a Computational Power-driven Material Flow Analysis (CP-MFA) model to quantify electronic waste generation from AI servers supporting large language models between 2020-2030. Their approach used an 8-unit GPU server (Nvidia DGX H100 system) as a benchmark proxy, applying Moore's Law to project computational power intensity over time. They measured computational requirements in petaflop-seconds per day and assumed a standard 3-year server lifespan based on industry practices.\hfill \break

Moreover, the study by \citet{M.rauf2024}, collected data through analyzing content from major academic databases such as Google Scholar and Web of Science. Additional literature was obtained from reliable sources such as Elsevier, MDPI, and Scopus, ensuring a broad and credible base for the review.A wide range of keywords were used to discover related publications.  These include "conductive charging," "wireless charging," "standards," "infrastructure," "G2V and V2G technologies," "grid systems," "bi-directional power flow," "smart grids," "autonomous electric vehicles," "EV Battery management," or "Energy Optimization" .  This thorough keyword list reflects a concerted attempt to develop a holistic and interdisciplinary approach, progressing from specific technical factors to greater systemic and environmental concerns.  The systematic procedure includes an initial search that returned over 120 publications, from which 101 were carefully selected for the final review, based on their relevance and quality from "reputed journals and conferences".  This selection procedure includes a quality control component, providing legitimacy to the final report's results.

\subsection{Core Methodology and Algorithms} 
\citet{Wu2022} uses a Carbon Footprint Analysis framework that is designed to holistically estimate the carbon footprint of AI, taking into account the complete machine learning (ML) pipeline end-to-end: data collection, model exploration and experimentation, model training, model optimization and run-time inference, while also taking into account the emissions across the life cycle of hardware systems, from manufacturing to operational use (p. 2). The calculation mechanism is divided into two parts: operational carbon and embodied carbon. Operational carbon is calculated by measuring the total energy consumption, location-based carbon intensity for electricity grids, while using a Power Usage Effectiveness (PUE) factor of 1.1 (p. 5). On the other hand, embodied carbon (carbon footprint of AI hardware) is quantified using LCA (Life Cycle Analysis). GPU-based AI training systems are assumed to have a similar embodied footprint as Apple's 28-core CPU with dual AMD Radeon GPUs in production, while for CPU-only AI training systems are assumed to have half that amount.  Based on the characterization of model training and inference at Meta, an average utilization rate of 30\% to 60\% over the 3-5 year lifetime for servers (p. 5). Combining all metrics above, the embodied carbon footprint is estimated to be: 
\begin{equation}
	CO_2^{\text{embodied}} = \sum_i \frac{\text{Time}}{\text{Lifetime}} CO_2^{\text{embodied}}(AI_{\text{System}})(i)
\end{equation}

Building upon Wu et al.'s (2022) carbon footprint analysis framework that distinguishes between operational and embodied carbon, \citet{Zhuk2023}'s study further expands the methodology by incorporating ethical-legal considerations and non-energy ecological costs. The framework integrates a lifecycle assessment (LCA) method for quantifying embodied carbon in AI hardware, accounting for the full manufacturing-to-disposal chain, and includes additional environmental externalities such as e-waste accumulation and resource depletion. The operational carbon footprint is computed with energy consumption data adjusted for grid carbon intensity and power usage effectiveness (PUE). The methodology incorporates a multidisciplinary approach by combining quantitative carbon accounting with qualitative assessments of environmental justice, policy gaps, and ethical implications of AI deployment, thereby enabling a holistic evaluation of AI's environmental and societal impacts.\hfill \break

As for the study by \citet{wang_2024_ewaste}, they incorporated three main scenario categories: proliferation patterns (optimistic, moderate, conservative), circular economy strategies (lifespan extension, stepwise upgrading, module reuse), and technical barrier impacts (constant barriers, regional variations, combined with circular measures). Geographic analysis focused on three major regions - North America, East Asia, and Europe - with distribution based on existing LLM development patterns. The dynamic stock modeling approach calculated new server requirements by subtracting current computational stock from new demand, then dividing by individual server capacity.\hfill \break

According to \citet{M.rauf2024}, integrating Artificial Intelligence (AI) and Machine Learning (ML) is essential for modern Electric Vehicle (EV) development, moving from theoretical concepts to actual applications.   The literature offers several approaches for improving battery performance, increasing efficiency, and resolving complex energy management challenges.The reviewed research focuses on supervised learning models such as Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), Neural Networks (ANN), Decision Trees, Support Vector Machine (SVM), and k-nearest neighbors for predictive and forecasting applications, which are critical for estimating battery health and charging demand.The article lists Q-Learning (QL), Reinforcement Learning (RL), Deep Learning (DL), and Heuristic Algorithms such as the Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Differential Evaluation (DE), and Artificial Bee Colony (ABC) for real-time optimization and control, which are essential for energy management and charging schedules.\hfill \break

These techniques are employed across various functional aspects of the electric vehicle, including:
\begin{itemize}
    \item Battery Research and Development: AI/ML models are used to select materials and estimate crucial battery parameters including State-of-Health (SOH), State-of-Charge (SOC), and Remaining Useful Life.

    \item Energy Management and Optimization: AI-powered algorithms use real-time optimization and adaptive control to handle complicated energy management challenges.

    \item Predictive Maintenance: Data-based methodologies forecast the life cycle and maintenance requirements for both electrical and mechanical components.

    \item Charging and Discharging Scheduling: Various learning models are used to estimate and schedule charging demand, especially in dynamic pricing situations.
\end{itemize}
This comprehensive collection of algorithms and their implementations emphasizes AI's critical and sophisticated role in developing an interconnected, intelligent EV environment.

\section{Result}
\citet{Wu2022} presents an important finding: the authors' estimations reveal that when considering the entire life cycle, the split between the operational carbon and embodied carbon is roughly 70\% / 30\% respectively, for large-scale machine learning tasks (p. 5). This result is significant as it demonstrates that the manufacturing supply chain (embodied carbon) is a major contributor to AI's total environmental impact, a factor often overlooked in prior research that focused solely on electricity consumption. They also note that, after considering carbon-free energy sources such as solar, the operational carbon footprint can be reduced significantly, leaving the manufacturing carbon cost as the dominating source of AI's carbon footprint (p. 5). Furthermore, the results reveal that the source of operational carbon emissions varies significantly depending on the AI task. For a large-scale language model (LM), the inference phase was found to dominate the carbon footprint (65\%) In contrast, for deep learning recommendation models (RM1–RM5), the carbon footprint was split more evenly between the training and inference phases (pp. 4–5). This finding disproves the common assumption that model training is always the most carbon-intensive part of an AI model's life cycle.\hfill \break

\citet{Zhuk2023}'s analysis shows a range of environmental, ethical and politicallegal issues associated with the training, use and development of artificial intelligence, which consumes a significant amount of energy (mainly from non-renewable sources). This leads to an increase in carbon emissions and creates obstacles to further sustainable ecological development. Improper disposal of artificial intelligence equipment exacerbates the problem of e-waste and pollution of the planet, further damaging the environment. Errors in artificial intelligence algorithms and decision-making processes
lead to environmental injustice and inequality. AI technologies may disrupt
natural ecosystems, jeopardizing wildlife habitats and migration patterns.\hfill \break

Based on the study by \citet{wang_2024_ewaste}, the study reveals that generative artificial intelligence (GAI), particularly large language models (LLMs), will create a massive electronic waste (E-waste) challenge in the coming years. Using their Computational Power-driven Material Flow Analysis (CP-MFA) model, the researchers found that in an optimistic scenario where LLMs become ubiquitous, the end-of-service E-waste from AI servers could reach approximately 16 million tons by 2030, representing 11\% of global E-waste with a compound annual growth rate of 110\% - far exceeding the 2.8\% growth rate of conventional E-waste. This waste will be geographically concentrated in North America (58\%), East Asia (25\%), and Europe (14\%). The study demonstrates that circular economy strategies can significantly mitigate this impact, with lifespan extension proving most effective (reducing waste by 58\% or 9.3 million tons), followed by module reuse (21\% reduction). However, geopolitical technical barriers could increase E-waste generation by 39\% due to reduced computational efficiency. While this obsolete equipment contains valuable materials worth approximately \$70 billion that could be recycled, it also harbors substantial toxic substances including 917,000 tons of lead that pose serious environmental and health risks if not properly managed.\hfill \break

\citet{M.rauf2024} shows that the main environmental advantage of electric vehicles (EVs) is that they reduce tailpipe emissions. However, a comprehensive environmental analysis requires a lifecycle view. The evaluation finds that EVs have an environmental footprint, particularly due to the costly manufacturing of their critical components. Lithium-ion batteries and fuel cells are made by extracting raw materials including lithium, cobalt, and nickel, which can result in large greenhouse gas emissions.This lifecycle assessment shows that the full sustainability of the EV ecosystem is directly linked to the decarbonization of the electric grid.  The environmental benefits of EVs become even more obvious as the energy sources utilized for charging shift to renewables.  This illustrates the interdependence of these global concerns, with the success of the transportation industry's change dependent on a simultaneous transition in the energy sector.Furthermore, the role of artificial intelligence (AI) in this setting displays a dual dynamic.  While AI can help lower carbon footprints by optimizing energy use using complex algorithms that monitor factors like as traffic and driver behavior, it also creates new environmental challenges.  The manufacturing of AI hardware, as well as the enormous energy usage of data centers for training and running AI models, all contribute to increased energy demand and emissions.  As a result, a comprehensive assessment demonstrates that, while AI is a great instrument for improving EV sustainability, its environmental impact must be carefully managed to ensure a net positive impact on global climate.

\section{Discussions}
\subsection{Advantages of Research Methodologies Used}
The first paper that was covered is that of \citet{Wu2022}. The main advantage of their research is the use of real-world production data from Meta, one of the largest AI infrastructures in the world. This is crucial because it gives the findings credibility that would otherwise be unattainable using simulated data, or in a small-scale academic setting. It paints an accurate picture of what AI's carbon footprint is like in real-world environments, thus eliminating the need to cross-check their findings with other institutions. Moreover, the framework with which the carbon footprint is calculated is actionable, pragmatic and easy to understand. As opposed to a complete LCA, which is often overly complex and difficult to digest, the distinction of operational carbon and embodied carbon is straightforward and easy for non-technical people such as AI engineers and managers to comprehend.\hfill \break

The methodology used in \citet{Zhuk2023}'s research article offers several notable advantages. Its interdisciplinary approach holistically covers not only AI's direct operational carbon footprint but also incorporates lifecycle environmental costs such as hardware manufacturing, e-waste, and ecosystem impacts. Integrating ethical and legal perspectives broadens the scope to include societal and governance dimensions, which is crucial for framing sustainable AI development in a just and responsible manner. This comprehensive and systemic view transcends the limitations of narrowly quantitative carbon footprint studies, enabling a more nuanced understanding of AI's true environmental costs and policy implications.\hfill \break

The study by \citet{wang_2024_ewaste} addresses a previously understudied but important environmental impact of AI development. Its comprehensive scenario analysis and practical circular economy solutions provide valuable insights for policymakers and industry stakeholders. The researchers transparently acknowledge limitations and uncertainties, enhancing credibility.\hfill \break

According to \citet{M.rauf2024}, using a literature review as the research methodology for this issue has multiple benefits.   The technique enables the efficient and effective synthesis of a massive and constantly growing body of information, which is critical in a field that merges automotive engineering, computer science, and environmental policy. By evaluating over 100 articles from reputable, peer-reviewed databases, the authors were able to summarize the important developments, unresolved concerns, and ongoing challenges linked to EVs and AI without the need for time-consuming and expensive primary experiments.This provides a comprehensive, expert-level overview that is extremely beneficial to a wide range of consumers, including policymakers, industry professionals, and researchers.  For policymakers, the evaluation provides a comprehensive knowledge of the current level of technology and the key constraints preventing widespread implementation.  For academics, it provides as a fundamental knowledge base, identifying essential themes and, most critically, revealing critical gaps requiring further exploration.  The authors emphasize that their work is meant to help other academics "overcome the problems," emphasizing the review's position as a road map for future scholarly effort.

\subsection{Limitations of Research Methodologies Used}
Although the research conducted by \citet{Wu2022} is rigorous and remarkable, it lacks generalizability across different AI ecosystems. The research findings are largely derived from Meta, a multinational conglomerate with one of the most complete AI infrastructures in the world, and has massive investments and commitments to renewable energy. Therefore, the findings might not be applicable to other institutions and settings, such as smaller companies that do not have access to the same resources as Meta. Besides that, the calculation of the embodied carbon footprint is an estimation, not the actual value. Due to the lack of publicly available data from hardware manufacturers, the authors had to rely on proxy data from other companies for certain hardware components. For example, the research assumes that a GPU-based AI training system has the same carbon footprint as Apple's 28-core CPU with dual AMD Radeon GPUs (p. 5). As a result, the actual embodied carbon footprint could be higher or lower than the estimated value. Furthermore, the research framework does not take into account the end-of-life phase for hardware components, which results in the oversight of the carbon emissions produced when hardware is incinerated or left to decompose in landfills.\hfill \break

Despite its strengths, the methodology in \citet{Zhuk2023}'s research article lacks formal quantitative modeling or formulaic analysis constrains the precision and reproducibility of environmental impact estimates, making it difficult to benchmark findings against other lifecycle assessments. The research primarily relies on secondary data and existing literature, which may limit measurement accuracy and fail to capture emerging empirical evidence from real-time AI deployments. Additionally, the complexity of integrating ethical-legal issues poses challenges for producing clear actionable outcomes and practical guidelines for AI developers and policymakers.\hfill \break

Regarding the weaknesses of the study by \citet{wang_2024_ewaste}, one of them is the significant data quality concerns that limit the findings' precision. Server deployment numbers rely on approximations due to proprietary industry data restrictions. The authors acknowledge "rough parameter configurations" and employ fixed assumptions like constant GPU-server computational power intensity that may not reflect technological evolution. The wide uncertainty range (8-16 million tons cumulative waste) indicates substantial estimation challenges. Methodological limitations include narrow scope (excluding cooling systems and ancillary infrastructure), geographic bias toward three established regions, and static lifespan assumptions that ignore operational variations. The heavy reliance on Moore's Law for exponential growth projections may not hold long-term, while circular economy implementation rates in practice may differ significantly from modeled scenarios.\hfill \break

The chosen research methodology \citet{M.rauf2024}, while beneficial, has inherent limits.  As a literature review, the study summarizes current information without producing new data or testing new hypotheses.  It provides a picture of current level of knowledge, which in a field as dynamic as AI and EV technology can become out of date soon.  The authors accept this restriction, stating that their "categorization of methodologies and standards may be investigated and improved by scholars at a later time".  This demonstrates that the review is a starting point for future investigation rather than a definite final declaration.

\subsection{Contribution of the Research}
\citet{Wu2022} presents a practical and industry-tested framework for quantifying AI's carbon footprint. Although the concept of operational and embodied carbon had been introduced prior, the paper puts a credible, industrial-scale number on it, estimating the embodied carbon accounts for at least 30\% of the total emissions (p. 5). It lays the foundation for more discussion and research on the subject of reducing the carbon emissions of hardware components. Secondly, beyond quantifying the problem, a significant contribution of the research is its demonstration of a practical, industry-tested strategy for mitigating AI's carbon footprint. The authors advocate for an approach of continuous hardware-software co-design, which they present not as a single solution but as an iterative, full-stack optimization process (p. 5). The efficacy of this strategy is illustrated through a case study where the operational carbon footprint of a language model was reduced by over 800 times (p. 6). This was not a single optimization but a series of compounding gains across different layers. At the software and platform layers, optimizations included application-level caching (a 6.7x efficiency improvement) and algorithmic techniques like numerical optimization to 16-bit precision (a 2.4x gain) and the use of custom GPU operators (a 5x gain) (p. 6). These efforts were then amplified at the hardware layer, where migrating the optimized workload to specialized GPUs provided an additional 10.1x improvement in energy efficiency. This case study effectively demonstrates that substantial sustainability gains are achieved when optimizations are made cohesively across all levels of the technology stack.\hfill \break

\citet{Zhuk2023}'s article significantly contributes to the field by emphasizing the hidden ecological costs and linking AI sustainability with environmental justice and regulatory requirements. The holistic framing invites multidisciplinary collaboration and calls for binding ethical-legal frameworks, renewable energy adoption, and responsible e-waste policies. This foundational work lays the groundwork for future studies to combine qualitative depth with rigorous quantitative lifecycle analyses and policy modeling, fostering AI innovation aligned with ecological and social sustainability goals.\hfill \break

Despite constraints of the study by \citet{wang_2024_ewaste}, the research succeeds in quantifying the scale of an emerging environmental challenge and identifying actionable mitigation strategies. While the high uncertainty levels prevent precise predictions, the work provides essential baseline estimates for policy discussions and highlights the urgent need for circular economy measures in AI infrastructure development.\hfill \break

This research \citet{M.rauf2024} focuses on synthesizing and arranging existing knowledge from various sources into a comprehensive framework, rather than discovering new data.  The report gives a complete review of present and developing EV charging methods, as well as compatible standards, which is critical for understanding the current technology environment and prospective adaption paths.  By examining how Artificial Intelligence is being used to various parts of EV development—from internal vehicle systems to external grid integration—the study highlights AI's critical role in producing a more efficient and smarter vehicle package.Furthermore, the study contributes to the body of knowledge by meticulously categorizing difficult procedures and standards, resulting in a valuable reference point that other researchers can investigate and build upon.  In this approach, the study acts as a key link across various sectors, providing a cohesive perspective on the issues and solutions confronting the EV business.

\section{Conclusion}
Conclusion of the work presented in the reviewed research papers.

\section{Future work}
Although present studies provide useful insights, there are still significant gaps that future study should solve.  First, most findings are based on data from large technological enterprises; further research into smaller organizations and emerging regions is required to improve generalizability.  Lifecycle evaluations should also be enhanced with manufacturer-verified data and incorporate end-of-life considerations such as recycling and landfill consequences, which are sometimes ignored.Beyond carbon measurements, future research should incorporate environmental, ethical, and legal perspectives to address concerns of equity and control.  More scientific proof is needed to validate proposed circular economy approaches to AI infrastructure, and research on EVs should look further into the balance between AI's environmental costs and advantages for sustainable mobility and renewable energy integration.  Finally, as AI systems progress toward centralized and advanced computing models, international cooperation on regulations for carbon reduction, e-waste management, and responsible AI deployment will become ever more essential.

%References
\printbibliography

\end{document}
