\documentclass[a4paper, 12pt]{article}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage[style=apa,backend=biber,natbib=true]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage{enumerate}
\usepackage{amsmath} 
\usepackage[margin=0.5in]{geometry}

\addbibresource{main.bib}


\renewcommand{\baselinestretch}{1.0}

\newcommand\nd{\textsuperscript{nd}\xspace}
\newcommand\rd{\textsuperscript{rd}\xspace}
\newcommand\nth{\textsuperscript{th}\xspace} %\th is taken already

\setlength\parindent{24pt} % set paragraph indent to zero

% fill up your name, ID and paper title here
\author{
IZZMINHAL AKMAL BIN NORHISYAM \quad 242UC240JF \quad contribution1 \\
CHOW YING TONG \quad 242UC244NK \quad contribution2\\
CHOONG JIA XUEN \quad 242UC244K1 \quad contribution3\\
LIM YU XUAN \quad 251UC18043 \quad contribution4\\
}
\title{ REVIEW REPORT  Title  }



\begin{document}
\maketitle


\section{Introduction and Problem Statement}
Artificial intelligence (AI) is undeniably experiencing a rapid growth. This is reflected in the massive increase in the computational resources required to train the latest models. According to \citet{Sevilla_Roldan_2024}, the amount of computational power needed to train the most advanced AI models is growing at a rate of 4 to 5 times per year. This exponential growth means that the environmental impact of AI, which is often overlooked, is compounded even further.

\section{Literature Review}
\subsection{Holistically Analyzing the Carbon Footprint of AI}
The work by \citet{Wu2022} provides a foundational, holistic analysis of the sources of AI's greenhouse gas emissions, shifting the focus beyond prior research that was often limited to the carbon footprint of training a single, massive model. The authors contend that this narrow, model-centric view has become insufficient in the face of the "super-linear growth" of the entire AI ecosystem, a trend characterized by exponential increases in model complexity, vast volumes of training data, and the ever-expanding hardware infrastructure required to support them (p.~2). To provide a more accurate assessment, their analysis expands the scope to encompass two critical dimensions: the end-to-end machine learning pipeline (from data acquisition to inference) and the life cycle of the hardware itself. Critically, they introduce a practical framework that distinguishes between operational carbon, defined as the emissions from electricity consumed during use, and embodied carbon, which are the often-hidden emissions generated from the entire manufacturing supply chain (p.~2). Other than that, they provide several solutions that could be employed to mitigate the carbon footprint of AI.

\subsection{Holistically Analyzing the Ecological Costs of AI}
The existing body of literature around artificial intelligence's environmental impacts showcases a widening concern over both visible and hidden costs associated with AI deployment. \citet{Zhuk2023} reveals that while computational energy consumption is commonly recognized as a major factor, studies often neglect the broader scope encompassing embodied emissions, resource extraction, waste production, and ethical implications. Quantitative life cycle assessments emphasize the vast electricity consumed by data centers for AI model training and inference, which significantly contributes to global greenhouse gas emissions \citep{Zhuk2023}. Additionally, AI's requirement for specialized hardware leads to increased electronic waste and environmental degradation tied to the mining of rare earth metals and disposal challenges, thereby multiplying the ecological footprint beyond operational energy use. The literature also integrates interdisciplinary perspectives that critically examine how algorithmic biases and automated decision-making exacerbate environmental inequalities, disproportionately affecting vulnerable socio-ecological systems lacking regulatory protections. The literature synthesis in \citet{Zhuk2023} positions AI's environmental challenges within a socio-technical regime, demanding analytical frameworks that balance technological benefits against ethical dilemmas, thereby bridging gaps between environmental science, ethics, and governance research (pp.~935--940).
\subsection{Holistically Analyzing the EVs, AI, and Sustainable Mobility}
The work by \citet{M.rauf2024} offers Global environmental challenges have put tremendous pressure on the transportation sector to transform.  Road transport, which includes more than one billion cars, is a major source of fossil fuel consumption and CO2 emissions, accounting for nearly 90 percent of total road traffic. This dependency is a great problem, given that global CO2 emissions are expected to exceed 37 billion tons in 2023. In addition to that, widespread usage of electric vehicles (EVs), which currently number 26 million worldwide, is an essential move toward meeting the Sustainable Development Goals (SDGs) and Net Zero Emission targets.  The success of this transition is directly related to the use of Artificial Intelligence (AI), which provides intelligent solutions for creating more affordable and efficient EVs. The influence of AI is visible throughout the EV ecosystem. It improves vehicle efficiency by utilizing advanced driver-assistance systems (ADAS) that optimize driving and manage energy use in real time.  Furthermore, AI is critical for grid integration since it allows Vehicle-to-Grid (V2G) systems to intelligently arrange energy exchanges, balance grid loads, and engage vehicle owners in energy programs.

\subsection{Holistically Analyzing the Contribution of AI towards E-Waste Generation}
Generative Artificial Intelligence (GAI), particularly Large Language Models (LLMs), demands intense computational power for training and inference, leading to substantial electronic waste (e-waste) with significant environmental implications. \citet{wang_2024_ewaste} proposes a Computational Power-driven Material Flow Analysis (CP-MFA) model to quantify e-waste from AI servers supporting LLMs, estimating that cumulative end-of-service e-waste may reach 16 million tons by 2030 in an optimistic scenario, constituting about 11\% of global e-waste. This e-waste is geographically concentrated mainly in North America, Europe, and East Asia, with a compound annual growth rate of 110\%, far exceeding conventional e-waste growth. The study explores three circular economy strategies—lifespan extension, stepwise upgrading, and module reuse—with lifespan extension proving most effective, potentially reducing e-waste by 58\%. Geopolitical factors, such as semiconductor trade restrictions, can increase e-waste due to lagged computational power and lower hardware efficiency. The discarded servers contain valuable metals (e.g., gold, silver, platinum) and toxic substances (e.g., lead, cadmium), highlighting both economic recycling potential (\~\$70 billion worth of materials) and environmental risks, including soil and water contamination. They emphasize the imperative for sustainable dismantling, recycling technologies, and circular economy implementation in the AI server life cycle. Additionally, repurposing functional outdated servers for smaller-scale educational or enterprise uses is encouraged to extend device utility. Major industry players have begun implementing zero-landfill goals and circular centers for efficient server recycling. The study calls for improved traceability, standardized server status labeling, and integrated recycling systems to manage the concentrated AI hardware waste effectively. Despite some modeling assumptions and uncertainties, the work highlights urgent environmental considerations intrinsic to the GAI boom and advocates multi-faceted strategies including international cooperation, circular economy adoption, and enhanced recycling infrastructure to mitigate the influx of AI-generated e-waste.

\section{Research Methodology}
\subsection{Data Collection and Sourcing}
Based on the study conducted by \citet{Wu2022}, the data was collected from multiple sources, from internal production systems at Meta, external public reports, and experimental modeling to create a holistic view of AI's environmental footprint. The primary data source consisted of extensive internal infrastructure telemetry from Meta's large-scale AI systems, encompassing operational metrics such as data center power consumption logs, GPU utilization rates, model training job durations, and data ingestion bandwidth statistics. To account for the manufacturing footprint, the authors sourced Life Cycle Inventory (LCI) data from external databases and manufacturer publications, such as Apple's Product Environmental Reports, which served as a proxy for their own hardware components (p.~5). For the purpose of comparative analysis, the study also incorporated the publicly available carbon footprint results of other prominent models, including GPT-3 and Meena, to contextualize their own findings (p.~5). Finally, to model the energy consumption of specific edge-computing use cases like federated learning, the authors constructed their estimations using a combination of experimental measurements, including device power profiles from Android (p.~19) and network bandwidth data from public sources.\hfill \break
\par The core methodologies related to data collection and sourcing used in \citet{Zhuk2023}'s research focus on a comprehensive secondary data synthesis approach. The author aggregates and evaluates empirical data from a wide range of life cycle assessments, energy consumption reports from AI data centers, and environmental studies on hardware manufacturing and electronic waste management. These data sources include governmental and institutional environmental reports, academic studies, and industry disclosures about AI infrastructure. This method allows the research to build a holistic picture of AI’s hidden ecological costs by integrating operational power use, embodied carbon footprints, and environmental justice considerations related to resource extraction and pollution. The author emphasizes the importance of combining quantitative environmental data with qualitative reflections on socio-economic disparities and regulatory frameworks to fully address AI’s environmental impacts (pp.~20--22). \hfill \break
\par In the study by \citet{wang_2024_ewaste}, the researchers developed a Computational Power-driven Material Flow Analysis (CP-MFA) model to quantify electronic waste generation from AI servers supporting large language models between 2020-2030. Their approach used an 8-unit GPU server (Nvidia DGX H100 system) as a benchmark proxy, applying Moore's Law to project computational power intensity over time. They measured computational requirements in petaflop-seconds per day and assumed a standard 3-year server lifespan based on industry practices. \hfill \break
\par Moreover, the study by \citet{M.rauf2024}, collected data through analyzing content from major academic databases such as Google Scholar and Web of Science. Additional literature was obtained from reliable sources such as Elsevier, MDPI, and Scopus, ensuring a broad and credible base for the review. A wide range of keywords were used to discover related publications. These include "conductive charging," "wireless charging," "standards," "infrastructure," "G2V and V2G technologies," "grid systems," "bi-directional power flow," "smart grids," "autonomous electric vehicles," "EV Battery management," or "Energy Optimization" .  This thorough keyword list reflects a concerted attempt to develop a holistic and interdisciplinary approach, progressing from specific technical factors to greater systemic and environmental concerns.  The systematic procedure includes an initial search that returned over 120 publications, from which 101 were carefully selected for the final review, based on their relevance and quality from "reputed journals and conferences".  This selection procedure includes a quality control component, providing legitimacy to the final report's results.

\subsection{Core Methodology and Algorithms} 
\citet{Wu2022} uses a Carbon Footprint Analysis framework that is designed to holistically estimate the carbon footprint of AI, taking into account the complete machine learning (ML) pipeline end-to-end: data collection, model exploration and experimentation, model training, model optimization and run-time inference, while also taking into account the emissions across the life cycle of hardware systems, from manufacturing to operational use (p.~2). The calculation mechanism is divided into two parts: operational carbon and embodied carbon. Operational carbon is calculated by measuring the total energy consumption, location-based carbon intensity for electricity grids, while using a Power Usage Effectiveness (PUE) factor of 1.1 (p.~5). On the other hand, embodied carbon (carbon footprint of AI hardware) is quantified using LCA (Life Cycle Analysis). GPU-based AI training systems are assumed to have a similar embodied footprint as Apple's 28-core CPU with dual AMD Radeon GPUs in production, while for CPU-only AI training systems are assumed to have half that amount.  Based on the characterization of model training and inference at Meta, an average utilization rate of 30\% to 60\% over the 3-5 year lifetime for servers (p.~5). Combining all metrics above, the embodied carbon footprint is estimated to be: 
\begin{equation}
	CO_2^{\text{embodied}} = \sum_i \frac{\text{Time}}{\text{Lifetime}} CO_2^{\text{embodied}}(AI_{\text{System}})(i)
\end{equation}

\par \citet{Zhuk2023} employs a conceptual, interdisciplinary analytical framework that includes systems analysis and normative legal-ethical critique rather than implementing computational algorithms directly. The research critically reviews algorithmic bias, error propagation, and their implications for environmental injustice, drawing from existing literature on algorithmic transparency and fairness. Additionally, while the study discusses state-of-the-art algorithmic efficiency techniques such as model quantization, pruning, and distributed training from relevant empirical work, these are treated descriptively to frame potential mitigation strategies against AI’s resource intensiveness. Life cycle assessment algorithms from external studies are incorporated indirectly, informing the environmental impact estimates. This fusion of scientific data interpretation with ethical and legal analysis forms the backbone of the study’s policy and governance recommendations designed to promote sustainable and equitable AI development (pp.~25--29). \hfill \break
\par As for the study by \citet{wang_2024_ewaste}, they incorporated three main scenario categories: proliferation patterns (optimistic, moderate, conservative), circular economy strategies (lifespan extension, stepwise upgrading, module reuse), and technical barrier impacts (constant barriers, regional variations, combined with circular measures). Geographic analysis focused on three major regions - North America, East Asia, and Europe - with distribution based on existing LLM development patterns. The dynamic stock modeling approach calculated new server requirements by subtracting current computational stock from new demand, then dividing by individual server capacity. \hfill \break
\par According to \citet{M.rauf2024}, integrating Artificial Intelligence (AI) and Machine Learning (ML) is essential for modern Electric Vehicle (EV) development, moving from theoretical concepts to actual applications.   The literature offers several approaches for improving battery performance, increasing efficiency, and resolving complex energy management challenges.The reviewed research focuses on supervised learning models such as Long Short-Term Memory (LSTM), Gated Recurrent Units (GRUs), Neural Networks (ANN), Decision Trees, Support Vector Machine (SVM), and k-nearest neighbors for predictive and forecasting applications, which are critical for estimating battery health and charging demand.The article lists Q-Learning (QL), Reinforcement Learning (RL), Deep Learning (DL), and Heuristic Algorithms such as the Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Differential Evaluation (DE), and Artificial Bee Colony (ABC) for real-time optimization and control, which are essential for energy management and charging schedules.\hfill \break

These techniques are employed across various functional aspects of the electric vehicle, including:
\begin{itemize}
    \item Battery Research and Development: AI/ML models are used to select materials and estimate crucial battery parameters including State-of-Health (SOH), State-of-Charge (SOC), and Remaining Useful Life.

    \item Energy Management and Optimization: AI-powered algorithms use real-time optimization and adaptive control to handle complicated energy management challenges.

    \item Predictive Maintenance: Data-based methodologies forecast the life cycle and maintenance requirements for both electrical and mechanical components.

    \item Charging and Discharging Scheduling: Various learning models are used to estimate and schedule charging demand, especially in dynamic pricing situations.
\end{itemize}
This comprehensive collection of algorithms and their implementations emphasizes AI's critical and sophisticated role in developing an interconnected, intelligent EV environment.

\section{Result}
\citet{Wu2022} presents an important finding: the authors' estimations reveal that when considering the entire life cycle, the split between the operational carbon and embodied carbon is roughly 70\% / 30\% respectively, for large-scale machine learning tasks (p.~5). This result is significant as it demonstrates that the manufacturing supply chain (embodied carbon) is a major contributor to AI's total environmental impact, a factor often overlooked in prior research that focused solely on electricity consumption. They also note that, after considering carbon-free energy sources such as solar, the operational carbon footprint can be reduced significantly, leaving the manufacturing carbon cost as the dominating source of AI's carbon footprint (p.~5). Furthermore, the results reveal that the source of operational carbon emissions varies significantly depending on the AI task. For a large-scale language model (LM), the inference phase was found to dominate the carbon footprint (65\%) In contrast, for deep learning recommendation models (RM1–RM5), the carbon footprint was split more evenly between the training and inference phases (pp.~4--5). This finding disproves the common assumption that model training is always the most carbon-intensive part of an AI model's life cycle.\hfill \break

\par The article presents a nuanced outcome revealing that AI's environmental footprint is multifarious and significant, characterized by operational and embodied impacts that demand urgent attention. \citet{Zhuk2023} highlights that AI systems, especially large-scale machine learning models, are resource-intensive, contributing to escalating energy demands and carbon emissions predominantly sourced from fossil-fuel-dependent power grids. Beyond this, the production and disposal of AI hardware bring substantial ecological costs through mining, pollution, and hazardous waste. The research also surfaces that AI exacerbates environmental inequities, as disadvantaged communities disproportionately experience the fallout of resource extraction and pollution correlated with AI infrastructure expansion. Additionally, the work identifies substantial regulatory gaps: many countries lack enforceable environmental standards tailored to AI technology, with ethical considerations rarely codified into binding legal commitments. These outcomes collectively demonstrate AI's paradoxical role as both an enabler of sustainable development applications and a contributor to new environmental and social challenges (pp.~950--955). \hfill \break
\par Based on the study by \citet{wang_2024_ewaste}, the study reveals that generative artificial intelligence (GAI), particularly large language models (LLMs), will create a massive electronic waste (E-waste) challenge in the coming years. Using their Computational Power-driven Material Flow Analysis (CP-MFA) model, the researchers found that in an optimistic scenario where LLMs become ubiquitous, the end-of-service E-waste from AI servers could reach approximately 16 million tons by 2030, representing 11\% of global E-waste with a compound annual growth rate of 110\% - far exceeding the 2.8\% growth rate of conventional E-waste. This waste will be geographically concentrated in North America (58\%), East Asia (25\%), and Europe (14\%). The study demonstrates that circular economy strategies can significantly mitigate this impact, with lifespan extension proving most effective (reducing waste by 58\% or 9.3 million tons), followed by module reuse (21\% reduction). However, geopolitical technical barriers could increase E-waste generation by 39\% due to reduced computational efficiency. While this obsolete equipment contains valuable materials worth approximately \$70 billion that could be recycled, it also harbors substantial toxic substances including 917,000 tons of lead that pose serious environmental and health risks if not properly managed.\hfill \break 
\par \citet{M.rauf2024} shows that the main environmental advantage of electric vehicles (EVs) is that they reduce tailpipe emissions. However, a comprehensive environmental analysis requires a life cycle view. The evaluation finds that EVs have an environmental footprint, particularly due to the costly manufacturing of their critical components. Lithium-ion batteries and fuel cells are made by extracting raw materials including lithium, cobalt, and nickel, which can result in large greenhouse gas emissions.This life cycle assessment shows that the full sustainability of the EV ecosystem is directly linked to the decarbonization of the electric grid.  The environmental benefits of EVs become even more obvious as the energy sources utilized for charging shift to renewables.  This illustrates the interdependence of these global concerns, with the success of the transportation industry's change dependent on a simultaneous transition in the energy sector.Furthermore, the role of artificial intelligence (AI) in this setting displays a dual dynamic.  While AI can help lower carbon footprints by optimizing energy use using complex algorithms that monitor factors like as traffic and driver behavior, it also creates new environmental challenges.  The manufacturing of AI hardware, as well as the enormous energy usage of data centers for training and running AI models, all contribute to increased energy demand and emissions.  As a result, a comprehensive assessment demonstrates that, while AI is a great instrument for improving EV sustainability, its environmental impact must be carefully managed to ensure a net positive impact on global climate.

\section{Discussions}
\subsection{Advantages of Research Methodologies Used}
The first paper that was covered is that of \citet{Wu2022}. The main advantage of their research is the use of real-world production data from Meta, one of the largest AI infrastructures in the world. This is crucial because it gives the findings credibility that would otherwise be unattainable using simulated data, or in a small-scale academic setting. It paints an accurate picture of what AI's carbon footprint is like in real-world environments, thus eliminating the need to cross-check their findings with other institutions. Moreover, the framework with which the carbon footprint is calculated is actionable, pragmatic and easy to understand. As opposed to a complete LCA, which is often overly complex and difficult to digest, the distinction of operational carbon and embodied carbon is straightforward and easy for non-technical people such as AI engineers and managers to comprehend.\hfill \break

\par One primary advantage of \citet{Zhuk2023}'s research methodology is the broad, interdisciplinary lens that brings together diverse fields such as environmental science, ethics, and law to analyze AI’s environmental impacts holistically. This integrated approach captures hidden ecological costs often omitted in conventional life cycle or energy-focused studies, offering a layered understanding of AI's footprint. Through critical literature synthesis, the research highlights socio-ethical dimensions, particularly environmental justice implications, which are crucial for equitable policy formulation. The conceptual framework enables bridging technical data and normative discussions, providing a foundation for future legal reforms and sustainable AI design principles. This methodological flexibility facilitates adaptation to the evolving technology landscape while incorporating public policy considerations, thus amplifying the study’s relevance and impact across multiple stakeholder groups (pp.~960--963). \hfill \break
\par The study by \cite{wang_2024_ewaste} addresses a previously understudied but important environmental impact of AI development. Its comprehensive scenario analysis and practical circular economy solutions provide valuable insights for policymakers and industry stakeholders. The researchers transparently acknowledge limitations and uncertainties, enhancing credibility. \hfill \break
\par According to \citet{M.rauf2024}, using a literature review as the research methodology for this issue has multiple benefits. The technique enables the efficient and effective synthesis of a massive and constantly growing body of information, which is critical in a field that merges automotive engineering, computer science, and environmental policy. By evaluating over 100 articles from reputable, peer-reviewed databases, the authors were able to summarize the important developments, unresolved concerns, and ongoing challenges linked to EVs and AI without the need for time-consuming and expensive primary experiments.This provides a comprehensive, expert-level overview that is extremely beneficial to a wide range of consumers, including policymakers, industry professionals, and researchers.  For policymakers, the evaluation provides a comprehensive knowledge of the current level of technology and the key constraints preventing widespread implementation.  For academics, it provides as a fundamental knowledge base, identifying essential themes and, most critically, revealing critical gaps requiring further exploration.  The authors emphasize that their work is meant to help other academics "overcome the problems," emphasizing the review's position as a road map for future scholarly effort.

\subsection{Limitations of Research Methodologies Used}
Although the research conducted by \citet{Wu2022} is rigorous and remarkable, it lacks generalizability across different AI ecosystems. The research findings are largely derived from Meta, a multinational conglomerate with one of the most complete AI infrastructures in the world, and has massive investments and commitments to renewable energy. Therefore, the findings might not be applicable to other institutions and settings, such as smaller companies that do not have access to the same resources as Meta. Besides that, the calculation of the embodied carbon footprint is an estimation, not the actual value. Due to the lack of publicly available data from hardware manufacturers, the authors had to rely on proxy data from other companies for certain hardware components. For example, the research assumes that a GPU-based AI training system has the same carbon footprint as Apple's 28-core CPU with dual AMD Radeon GPUs (p.~5). As a result, the actual embodied carbon footprint could be higher or lower than the estimated value. Furthermore, the research framework does not take into account the end-of-life phase for hardware components, which results in the oversight of the carbon emissions produced when hardware is incinerated or left to decompose in landfills.\hfill \break

\par Despite its strengths, the research methodology of \citet{Zhuk2023} shows limitations inherent to conceptual and secondary data reliance. The absence of original empirical measurements restricts precise quantification of AI’s environmental impacts, making some conclusions reliant on extrapolations from broader technological studies. Additionally, rapid AI technology advancements may cause some reviewed literature to become outdated, challenging the method’s capacity to reflect real-time dynamics. The normative critique, while invaluable, lacks actionable procedural models or concrete legal pathways, which may limit its immediate applicability in regulatory contexts. Furthermore, multi-level governance structures and socio-political complexities impacting AI deployment add layers of difficulty not fully resolved through literature-based analysis alone. Such limitations underscore the need for complementary empirical research and continuous policy engagement to operationalize the article’s insights effectively (pp.~964--967).\hfill \break
\par Regarding the weaknesses of the study by \citet{wang_2024_ewaste}, one of them is the significant data quality concerns that limit the findings' precision. Server deployment numbers rely on approximations due to proprietary industry data restrictions. The authors acknowledge "rough parameter configurations" and employ fixed assumptions like constant GPU-server computational power intensity that may not reflect technological evolution. The wide uncertainty range (8-16 million tons cumulative waste) indicates substantial estimation challenges. Methodological limitations include narrow scope (excluding cooling systems and ancillary infrastructure), geographic bias toward three established regions, and static lifespan assumptions that ignore operational variations. The heavy reliance on Moore's Law for exponential growth projections may not hold long-term, while circular economy implementation rates in practice may differ significantly from modeled scenarios. \hfill \break
\par The chosen research methodology \citet{M.rauf2024}, while beneficial, has inherent limits.  As a literature review, the study summarizes current information without producing new data or testing new hypotheses.  It provides a picture of current level of knowledge, which in a field as dynamic as AI and EV technology can become out of date soon.  The authors accept this restriction, stating that their "categorization of methodologies and standards may be investigated and improved by scholars at a later time".  This demonstrates that the review is a starting point for future investigation rather than a definite final declaration. \hfill \break

\subsection{Contribution of the Research}
\citet{Wu2022} presents a practical and industry-tested framework for quantifying AI's carbon footprint. Although the concept of operational and embodied carbon had been introduced prior, the paper puts a credible, industrial-scale number on it, estimating the embodied carbon accounts for at least 30\% of the total emissions (p.~5). It lays the foundation for more discussion and research on the subject of reducing the carbon emissions of hardware components. Secondly, beyond quantifying the problem, a significant contribution of the research is its demonstration of a practical, industry-tested strategy for mitigating AI's carbon footprint. The authors advocate for an approach of continuous hardware-software co-design, which they present not as a single solution but as an iterative, full-stack optimization process (p.~5). The efficacy of this strategy is illustrated through a case study where the operational carbon footprint of a language model was reduced by over 800 times (p.~6). This was not a single optimization but a series of compounding gains across different layers. At the software and platform layers, optimizations included application-level caching (a 6.7x efficiency improvement) and algorithmic techniques like numerical optimization to 16-bit precision (a 2.4x gain) and the use of custom GPU operators (a 5x gain) (p.~6). These efforts were then amplified at the hardware layer, where migrating the optimized workload to specialized GPUs provided an additional 10.1x improvement in energy efficiency. This case study effectively demonstrates that substantial sustainability gains are achieved when optimizations are made cohesively across all levels of the technology stack.\hfill \break

\par \citet{Zhuk2023} study makes a seminal contribution by reframing AI’s environmental challenges as intrinsically socio-technical and socio-legal, emphasizing hidden ecological costs and their intertwined ethical and governance issues. By integrating environmental science with normative legal analysis, the article highlights underexplored dimensions such as algorithmic bias as an environmental injustice and the inadequacy of existing legislation to manage AI’s footprint comprehensively. This innovative interdisciplinary perspective fosters a deeper, systemic understanding that extends beyond technical metrics to incorporate values of fairness and accountability. Moreover, the research offers guidance for developing integrated frameworks that could lead to enforceable policies promoting sustainable and equitable AI development. By raising critical awareness among policymakers, technologists, and environmental advocates, it advances the foundation for responsible AI governance in the context of planetary ecological limits (pp.~968--970). \hfill \break
\par Despite constraints of the study by \citet{wang_2024_ewaste}, the research succeeds in quantifying the scale of an emerging environmental challenge and identifying actionable mitigation strategies. While the high uncertainty levels prevent precise predictions, the work provides essential baseline estimates for policy discussions and highlights the urgent need for circular economy measures in AI infrastructure development.
This research \citet{M.rauf2024} focuses on synthesizing and arranging existing knowledge from various sources into a comprehensive framework, rather than discovering new data.  The report gives a complete review of present and developing EV charging methods, as well as compatible standards, which is critical for understanding the current technology environment and prospective adaption paths.  By examining how Artificial Intelligence is being used to various parts of EV development—from internal vehicle systems to external grid integration—the study highlights AI's critical role in producing a more efficient and smarter vehicle package.Furthermore, the study contributes to the body of knowledge by meticulously categorizing difficult procedures and standards, resulting in a valuable reference point that other researchers can investigate and build upon.  In this approach, the study acts as a key link across various sectors, providing a cohesive perspective on the issues and solutions confronting the EV business.

\section{Conclusion}
Conclusion of the work presented in the reviewed research papers.

\section{Future work}
Although present studies provide useful insights, there are still significant gaps that future study should solve. First, most findings are based on data from large technological enterprises; further research into smaller organizations and emerging regions is required to improve generalizability.  Life cycle evaluations should also be enhanced with manufacturer-verified data and incorporate end-of-life considerations such as recycling and landfill consequences, which are sometimes ignored. Beyond carbon measurements, future research should incorporate environmental, ethical, and legal perspectives to address concerns of equity and control.  More scientific proof is needed to validate proposed circular economy approaches to AI infrastructure, and research on EVs should look further into the balance between AI's environmental costs and advantages for sustainable mobility and renewable energy integration.  Finally, as AI systems progress toward centralized and advanced computing models, international cooperation on regulations for carbon reduction, e-waste management, and responsible AI deployment will become ever more essential.

%References
\printbibliography

\end{document}
