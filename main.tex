\documentclass[a4paper, 12pt]{article}
\usepackage[american]{babel}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage[style=apa,backend=biber,natbib=true]{biblatex}
\DeclareLanguageMapping{american}{american-apa}
\usepackage[T1]{fontenc}
\usepackage{mathptmx}
\usepackage{enumerate}
\usepackage{amsmath} 
\usepackage[margin=0.5in]{geometry}

\addbibresource{main.bib}


\renewcommand{\baselinestretch}{1.0}

\newcommand\nd{\textsuperscript{nd}\xspace}
\newcommand\rd{\textsuperscript{rd}\xspace}
\newcommand\nth{\textsuperscript{th}\xspace} %\th is taken already

\setlength\parindent{24pt} % set paragraph indent to zero

% fill up your name, ID and paper title here
\author{
IZZMINHAL AKMAL BIN NORHISYAM \quad 242UC240JF \quad contribution1 \\
CHOW YING TONG \quad 242UC244NK \quad contribution2\\
CHOONG JIA XUEN \quad 242UC244K1 \quad contribution3\\
Student Name4 \quad Student ID4 \quad contribution4\\
}
\title{ REVIEW REPORT  Title  }



\begin{document}
\maketitle


\section{Introduction and Problem Statement}
Write the introduction here. What is the background of the problem? Why is there a problem? What are the previous work/research to attempt the problem? 

Problem statement in a new paragraph, follow by objectives.

\section{Literature Review}
\subsection{Holistically Analyzing the Carbon Footprint of AI}
The work by \citet{Wu2022} provides a foundational, holistic analysis of the sources of AI's greenhouse gas emissions, shifting the focus beyond prior research that was often limited to the carbon footprint of training a single, massive model. The authors contend that this narrow, model-centric view has become insufficient in the face of the "super-linear growth" of the entire AI ecosystem, a trend characterized by exponential increases in model complexity, vast volumes of training data, and the ever-expanding hardware infrastructure required to support them (p. 2). To provide a more accurate assessment, their analysis expands the scope to encompass two critical dimensions: the end-to-end machine learning pipeline (from data acquisition to inference) and the life cycle of the hardware itself. Critically, the authors introduce a practical framework that distinguishes between operational carbon, defined as the emissions from electricity consumed during use, and embodied carbon, which are the often-hidden emissions generated from the entire manufacturing supply chain (p. 2). Other than that, the authors provide several solutions that could be employed to mitigate the carbon footprint of AI.

\subsection{Holistically Analyzing the Ecological Costs of AI}
The existing body of literature around artificial intelligence's environmental impacts showcases a widening concern over both visible and hidden costs associated with AI deployment. \citet{Zhuk2023} reveals that while computational energy consumption is commonly recognized as a major factor, studies often neglect the broader scope encompassing embodied emissions, resource extraction, waste production, and ethical implications. Quantitative lifecycle assessments emphasize the vast electricity consumed by data centers for AI model training and inference, which significantly contributes to global greenhouse gas emissions \citep{Zhuk2023}. Additionally, AI's requirement for specialized hardware leads to increased electronic waste and environmental degradation tied to the mining of rare earth metals and disposal challenges, thereby multiplying the ecological footprint beyond operational energy use. The literature also integrates interdisciplinary perspectives that critically examine how algorithmic biases and automated decision-making exacerbate environmental inequalities, disproportionately affecting vulnerable socio-ecological systems lacking regulatory protections. The literature synthesis in \citet{Zhuk2023} positions AI's environmental challenges within a socio-technical regime, demanding analytical frameworks that balance technological benefits against ethical dilemmas, thereby bridging gaps between environmental science, ethics, and governance research \citep[p.~935--940]{Zhuk2023}.
\section{Research Methodology}
\subsection{Data Collection and Sourcing}
Based on the study conducted by \citet{Wu2022}, the data was collected from multiple sources, from internal production systems at Meta, external public reports, and experimental modeling to create a holistic view of AI's environmental footprint. The primary data source consisted of extensive internal infrastructure telemetry from Meta's large-scale AI systems, encompassing operational metrics such as data center power consumption logs, GPU utilization rates, model training job durations, and data ingestion bandwidth statistics. To account for the manufacturing footprint, the authors sourced Life Cycle Inventory (LCI) data from external databases and manufacturer publications, such as Apple's Product Environmental Reports, which served as a proxy for their own hardware components (p. 5). For the purpose of comparative analysis, the study also incorporated the publicly available carbon footprint results of other prominent models, including GPT-3 and Meena, to contextualize their own findings (p. 5). Finally, to model the energy consumption of specific edge-computing use cases like federated learning, the authors constructed their estimations using a combination of experimental measurements, including device power profiles from Android (p. 19) and network bandwidth data from public sources.

\hspace{24pt}The core methodologies related to data collection and sourcing used in \citet{Zhuk2023}'s research focus on a comprehensive secondary data synthesis approach. The author aggregates and evaluates empirical data from a wide range of lifecycle assessments, energy consumption reports from AI data centers, and environmental studies on hardware manufacturing and electronic waste management. These data sources include governmental and institutional environmental reports, academic studies, and industry disclosures about AI infrastructure. This method allows the research to build a holistic picture of AI’s hidden ecological costs by integrating operational power use, embodied carbon footprints, and environmental justice considerations related to resource extraction and pollution. \citet{Zhuk2023} emphasizes the importance of combining quantitative environmental data with qualitative reflections on socio-economic disparities and regulatory frameworks to fully address AI’s environmental impacts \citep[pp.~20--22]{Zhuk2023}; see also \citep{OECD2022, MIT2025}.
\par In the study by \cite{wang_2024_ewaste} the researchers developed a Computational Power-driven Material Flow Analysis (CP-MFA) model to quantify electronic waste generation from AI servers supporting large language models between 2020-2030. Their approach used an 8-unit GPU server (Nvidia DGX H100 system) as a benchmark proxy, applying Moore's Law to project computational power intensity over time. They measured computational requirements in petaflop-seconds per day and assumed a standard 3-year server lifespan based on industry practices.

\subsection{Core Methodology and Algorithms} 
\citet{Wu2022} uses a Carbon Footprint Analysis framework that is designed to holistically estimate the carbon footprint of AI, taking into account the complete machine learning (ML) pipeline end-to-end: data collection, model exploration and experimentation, model training, model optimization and run-time inference, while also taking into account the emissions across the life cycle of hardware systems, from manufacturing to operational use (p. 2). The calculation mechanism is divided into two parts: operational carbon and embodied carbon. Operational carbon is calculated by measuring the total energy consumption, location-based carbon intensity for electricity grids, while using a Power Usage Effectiveness (PUE) factor of 1.1 (p. 5). On the other hand, embodied carbon (carbon footprint of AI hardware) is quantified using LCA (Life Cycle Analysis). GPU-based AI training systems are assumed to have a similar embodied footprint as Apple's 28-core CPU with dual AMD Radeon GPUs in production, while for CPU-only AI training systems are assumed to have half that amount.  Based on the characterization of model training and inference at Meta, an average utilization rate of 30\% to 60\% over the 3-5 year lifetime for servers (p. 5). Combining all metrics above, the embodied carbon footprint is estimated to be: 
\begin{equation}
	CO_2^{\text{embodied}} = \sum_i \frac{\text{Time}}{\text{Lifetime}} CO_2^{\text{embodied}}(AI_{\text{System}})(i)
\end{equation}

\par \citet{Zhuk2023} employs a conceptual, interdisciplinary analytical framework that includes systems analysis and normative legal-ethical critique rather than implementing computational algorithms directly. The research critically reviews algorithmic bias, error propagation, and their implications for environmental injustice, drawing from existing literature on algorithmic transparency and fairness. Additionally, while the study discusses state-of-the-art algorithmic efficiency techniques such as model quantization, pruning, and distributed training from relevant empirical work, these are treated descriptively to frame potential mitigation strategies against AI’s resource intensiveness. Lifecycle assessment algorithms from external studies are incorporated indirectly, informing the environmental impact estimates. This fusion of scientific data interpretation with ethical and legal analysis forms the backbone of the study’s policy and governance recommendations designed to promote sustainable and equitable AI development \citep[pp.~25--29]{Zhuk2023}.
\par As for the study by \cite{wang_2024_ewaste}, they incorporated three main scenario categories: proliferation patterns (optimistic, moderate, conservative), circular economy strategies (lifespan extension, stepwise upgrading, module reuse), and technical barrier impacts (constant barriers, regional variations, combined with circular measures). Geographic analysis focused on three major regions - North America, East Asia, and Europe - with distribution based on existing LLM development patterns. The dynamic stock modeling approach calculated new server requirements by subtracting current computational stock from new demand, then dividing by individual server capacity.

\section{Result}
\citet{Wu2022} presents an important finding: the authors' estimations reveal that when considering the entire life cycle, the split between the operational carbon and embodied carbon is roughly 70\% / 30\% respectively, for large-scale machine learning tasks (p. 5). This result is significant as it demonstrates that the manufacturing supply chain (embodied carbon) is a major contributor to AI's total environmental impact, a factor often overlooked in prior research that focused solely on electricity consumption. They also note that, after considering carbon-free energy sources such as solar, the operational carbon footprint can be reduced significantly, leaving the manufacturing carbon cost as the dominating source of AI's carbon footprint (p. 5). Furthermore, the results reveal that the source of operational carbon emissions varies significantly depending on the AI task. For a large-scale language model (LM), the inference phase was found to dominate the carbon footprint (65\%) In contrast, for deep learning recommendation models (RM1–RM5), the carbon footprint was split more evenly between the training and inference phases (pp. 4–5). This finding disproves the common assumption that model training is always the most carbon-intensive part of an AI model's life cycle.

\par The article presents a nuanced outcome revealing that AI's environmental footprint is multifarious and significant, characterized by operational and embodied impacts that demand urgent attention. \citet{Zhuk2023} highlights that AI systems, especially large-scale machine learning models, are resource-intensive, contributing to escalating energy demands and carbon emissions predominantly sourced from fossil-fuel-dependent power grids. Beyond this, the production and disposal of AI hardware bring substantial ecological costs through mining, pollution, and hazardous waste. The research also surfaces that AI exacerbates environmental inequities, as disadvantaged communities disproportionately experience the fallout of resource extraction and pollution correlated with AI infrastructure expansion. Additionally, the work identifies substantial regulatory gaps: many countries lack enforceable environmental standards tailored to AI technology, with ethical considerations rarely codified into binding legal commitments. These outcomes collectively demonstrate AI's paradoxical role as both an enabler of sustainable development applications and a contributor to new environmental and social challenges \citep[pp.~950--955]{Zhuk2023}.
\section{Discussions}
\subsection{Advantages of Research Methodologies Used}
The first paper that was covered is that of \citet{Wu2022}. The main advantage of their research is the use of real-world production data from Meta, one of the largest AI infrastructures in the world. This is crucial because it gives the findings credibility that would otherwise be unattainable using simulated data, or in a small-scale academic setting. It paints an accurate picture of what AI's carbon footprint is like in real-world environments, thus eliminating the need to cross-check their findings with other institutions. Moreover, the framework with which the carbon footprint is calculated is actionable, pragmatic and easy to understand. As opposed to a complete LCA, which is often overly complex and difficult to digest, the distinction of operational carbon and embodied carbon is straightforward and easy for non-technical people such as AI engineers and managers to comprehend.

\par One primary advantage of \citet{Zhuk2023}'s research methodology is the broad, interdisciplinary lens that brings together diverse fields such as environmental science, ethics, and law to analyze AI’s environmental impacts holistically. This integrated approach captures hidden ecological costs often omitted in conventional lifecycle or energy-focused studies, offering a layered understanding of AI's footprint. Through critical literature synthesis, the research highlights socio-ethical dimensions, particularly environmental justice implications, which are crucial for equitable policy formulation. The conceptual framework enables bridging technical data and normative discussions, providing a foundation for future legal reforms and sustainable AI design principles. This methodological flexibility facilitates adaptation to the evolving technology landscape while incorporating public policy considerations, thus amplifying the study’s relevance and impact across multiple stakeholder groups \citep[pp.~960--963]{Zhuk2023}.\par The study by \cite{wang_2024_ewaste} addresses a previously understudied but important environmental impact of AI development. Its comprehensive scenario analysis and practical circular economy solutions provide valuable insights for policymakers and industry stakeholders. The researchers transparently acknowledge limitations and uncertainties, enhancing credibility.

\subsection{Limitations of Research Methodologies Used}
Although the research conducted by \citet{Wu2022} is rigorous and remarkable, it lacks generalizability across different AI ecosystems. The research findings are largely derived from Meta, a multinational conglomerate with one of the most complete AI infrastructures in the world, and has massive investments and commitments to renewable energy. Therefore, the findings might not be applicable to other institutions and settings, such as smaller companies that do not have access to the same resources as Meta. Besides that, the calculation of the embodied carbon footprint is an estimation, not the actual value. Due to the lack of publicly available data from hardware manufacturers, the authors had to rely on proxy data from other companies for certain hardware components. For example, the research assumes that a GPU-based AI training system has the same carbon footprint as Apple's 28-core CPU with dual AMD Radeon GPUs (p. 5). As a result, the actual embodied carbon footprint could be higher or lower than the estimated value. Furthermore, the research framework does not take into account the end-of-life phase for hardware components, which results in the oversight of the carbon emissions produced when hardware is incinerated or left to decompose in landfills.

\par Despite its strengths, the research methodology of \citet{Zhuk2023} shows limitations inherent to conceptual and secondary data reliance. The absence of original empirical measurements restricts precise quantification of AI’s environmental impacts, making some conclusions reliant on extrapolations from broader technological studies. Additionally, rapid AI technology advancements may cause some reviewed literature to become outdated, challenging the method’s capacity to reflect real-time dynamics. The normative critique, while invaluable, lacks actionable procedural models or concrete legal pathways, which may limit its immediate applicability in regulatory contexts. Furthermore, multi-level governance structures and socio-political complexities impacting AI deployment add layers of difficulty not fully resolved through literature-based analysis alone. Such limitations underscore the need for complementary empirical research and continuous policy engagement to operationalize the article’s insights effectively \citep[pp.~964--967]{Zhuk2023}.
\par Regarding the weaknesses of the study by \cite{wang_2024_ewaste}, one of them is the significant data quality concerns that limit the findings' precision. Server deployment numbers rely on approximations due to proprietary industry data restrictions. The authors acknowledge "rough parameter configurations" and employ fixed assumptions like constant GPU-server computational power intensity that may not reflect technological evolution. The wide uncertainty range (8-16 million tons cumulative waste) indicates substantial estimation challenges. Methodological limitations include narrow scope (excluding cooling systems and ancillary infrastructure), geographic bias toward three established regions, and static lifespan assumptions that ignore operational variations. The heavy reliance on Moore's Law for exponential growth projections may not hold long-term, while circular economy implementation rates in practice may differ significantly from modeled scenarios.

\subsection{Contribution of the Research}
\citet{Wu2022} presents a practical and industry-tested framework for quantifying AI's carbon footprint. Although the concept of operational and embodied carbon had been introduced prior, the paper puts a credible, industrial-scale number on it, estimating the embodied carbon accounts for at least 30\% of the total emissions (p. 5). It lays the foundation for more discussion and research on the subject of reducing the carbon emissions of hardware components. Secondly, beyond quantifying the problem, a significant contribution of the research is its demonstration of a practical, industry-tested strategy for mitigating AI's carbon footprint. The authors advocate for an approach of continuous hardware-software co-design, which they present not as a single solution but as an iterative, full-stack optimization process (p. 5). The efficacy of this strategy is illustrated through a case study where the operational carbon footprint of a language model was reduced by over 800 times (p. 6). This was not a single optimization but a series of compounding gains across different layers. At the software and platform layers, optimizations included application-level caching (a 6.7x efficiency improvement) and algorithmic techniques like numerical optimization to 16-bit precision (a 2.4x gain) and the use of custom GPU operators (a 5x gain) (p. 6). These efforts were then amplified at the hardware layer, where migrating the optimized workload to specialized GPUs provided an additional 10.1x improvement in energy efficiency. This case study effectively demonstrates that substantial sustainability gains are achieved when optimizations are made cohesively across all levels of the technology stack.

\par \citet{Zhuk2023} study makes a seminal contribution by reframing AI’s environmental challenges as intrinsically socio-technical and socio-legal, emphasizing hidden ecological costs and their intertwined ethical and governance issues. By integrating environmental science with normative legal analysis, the article highlights underexplored dimensions such as algorithmic bias as an environmental injustice and the inadequacy of existing legislation to manage AI’s footprint comprehensively. This innovative interdisciplinary perspective fosters a deeper, systemic understanding that extends beyond technical metrics to incorporate values of fairness and accountability. Moreover, the research offers guidance for developing integrated frameworks that could lead to enforceable policies promoting sustainable and equitable AI development. By raising critical awareness among policymakers, technologists, and environmental advocates, it advances the foundation for responsible AI governance in the context of planetary ecological limits (Zhuk, 2023, pp. 968-970).
\par Despite constraints of the study by \cite{wang_2024_ewaste}, the research succeeds in quantifying the scale of an emerging environmental challenge and identifying actionable mitigation strategies. While the high uncertainty levels prevent precise predictions, the work provides essential baseline estimates for policy discussions and highlights the urgent need for circular economy measures in AI infrastructure development

\section{Conclusion}
Conclusion of the work presented in the reviewed research papers.

\section{Future work}
Some suggestions for improvement.

%References
\printbibliography

\end{document}
